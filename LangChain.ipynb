{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c4780ab",
   "metadata": {},
   "source": [
    "# LangChain\n",
    "\n",
    "- What is LangChain?\n",
    "- Type of prompts:\n",
    "\t- Simple Prompt\n",
    "\t- Message Prompt\n",
    "- Initialize LLM\n",
    "- Execute a prompt with LLM\n",
    "- What's included in LangChain\n",
    "- LangChain Expression Language (LCEL)\n",
    "- AI Agent\n",
    "- Structured Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd17324b",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## Simple Prompt in LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8269fed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------Normal Way-----------------------\n",
      "'Answer the user query in one line.\\n What is Gen AI?'\n",
      "------------LangChain way-----------------------\n",
      "StringPromptValue(text='Answer the user query in one line.\\nWhat is Gen AI?\\n')\n"
     ]
    }
   ],
   "source": [
    "## Prompt simple way\n",
    "import pprint\n",
    "\n",
    "print(\"------------Normal Way-----------------------\")\n",
    "prompt = \"Answer the user query in one line.\\n What is Gen AI?\"\n",
    "\n",
    "\n",
    "pprint.pprint(prompt)\n",
    "\n",
    "\n",
    "## LangChain way\n",
    "\n",
    "print(\"------------LangChain way-----------------------\")\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query in one line.\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    ")\n",
    "\n",
    "text_prompt = prompt.invoke({\"query\": \"What is Gen AI?\"})\n",
    "\n",
    "pprint.pprint(text_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10dba609",
   "metadata": {},
   "source": [
    "---\n",
    "## Message Prompt in LangChain\n",
    "This is new way of prompting in LLM. This follows simple chat like structure.\n",
    "```\n",
    "Me: How are you?\n",
    "LLM: I am fine.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c56195c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------Normal Way-----------------------\n",
      "[('system',\n",
      "  'You are a helpful assistant that translates English to French. Translate '\n",
      "  'the user sentence.'),\n",
      " ('human', 'I love programming.')]\n",
      "------------LangChain way-----------------------\n",
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "You are a helpful assistant that translates English to Hindi. Translate the user sentence.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I love programming.\n"
     ]
    }
   ],
   "source": [
    "## Chat Message simple way\n",
    "import pprint\n",
    "\n",
    "print(\"------------Normal Way-----------------------\")\n",
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that translates English to French. Translate the user sentence.\",\n",
    "    ),\n",
    "    (\"human\", \"I love programming.\"),\n",
    "]\n",
    "\n",
    "pprint.pprint(messages)\n",
    "\n",
    "\n",
    "## LangChain way\n",
    "\n",
    "print(\"------------LangChain way-----------------------\")\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "prompt_template = ChatPromptTemplate([\n",
    "    (\"system\", \"You are a helpful assistant that translates English to {language}. Translate the user sentence.\"),\n",
    "    MessagesPlaceholder(\"msgs\")\n",
    "])\n",
    "\n",
    "prompt_messages = prompt_template.invoke({\n",
    "    \"msgs\": [HumanMessage(content=\"I love programming.\")],\n",
    "    \"language\": \"Hindi\"\n",
    "})\n",
    "\n",
    "for message in prompt_messages.messages:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76a4a8e",
   "metadata": {},
   "source": [
    "---\n",
    "## Initialize LLM\n",
    "- LangChain provides different packages for integrating with different LLM's. \n",
    "- List can be seen in [Chat Model](https://python.langchain.com/docs/integrations/chat/)\n",
    "- Not all Chat Model support all the feature, so make sure you check if it's supported before using it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe69c048",
   "metadata": {},
   "outputs": [],
   "source": [
    "## initialize DeepSeek LLM\n",
    "\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "\n",
    "deepseek_llm = ChatDeepSeek(\n",
    "    model=\"deepseek-chat\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b96754a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## initialize OpenAI LLM\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "openai_llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e42d86",
   "metadata": {},
   "source": [
    "---\n",
    "## Execute a prompt with LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf401adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Gen AI is artificial intelligence that generates new content like text, images, or code based on input data.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "\n",
    "\n",
    "# Initialize a simple prompt\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query in one line.\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    ")\n",
    "\n",
    "text_prompt = prompt.invoke({\"query\": \"What is Gen AI?\"})\n",
    "\n",
    "## initialize DeepSeek LLM\n",
    "deepseek_llm = ChatDeepSeek(\n",
    "    model=\"deepseek-chat\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")\n",
    "\n",
    "## Execute a prompt with LLM\n",
    "response = deepseek_llm.invoke(text_prompt)\n",
    "response.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05081e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "J'adore programmer.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Initialize a chat prompt template\n",
    "prompt_template = ChatPromptTemplate([\n",
    "    (\"system\", \"You are a helpful assistant that translates English to {language}. Translate the user sentence.\"),\n",
    "    MessagesPlaceholder(\"msgs\")\n",
    "])\n",
    "\n",
    "prompt_messages = prompt_template.invoke({\n",
    "    \"msgs\": [HumanMessage(content=\"I love programming.\")],\n",
    "    \"language\": \"French\"\n",
    "})\n",
    "\n",
    "## initialize DeepSeek LLM\n",
    "deepseek_llm = ChatDeepSeek(\n",
    "    model=\"deepseek-chat\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")\n",
    "\n",
    "## Execute a prompt with LLM\n",
    "response = deepseek_llm.invoke(prompt_messages)\n",
    "response.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e551b9",
   "metadata": {},
   "source": [
    "---\n",
    "## LangChain Expression Language (LCEL)\n",
    "LCEL allows to write more readable code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b45bbb52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "J'adore la programmation.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "\n",
    "# Initialize a chat prompt template\n",
    "prompt_template = ChatPromptTemplate([\n",
    "    (\"system\", \"You are a helpful assistant that translates English to {language}. Translate the user sentence.\"),\n",
    "    MessagesPlaceholder(\"msgs\")\n",
    "])\n",
    "\n",
    "# prompt_messages = prompt_template.invoke({\n",
    "#     \"msgs\": [HumanMessage(content=\"I love programming.\")],\n",
    "#     \"language\": \"French\"\n",
    "# })\n",
    "\n",
    "## initialize DeepSeek LLM\n",
    "deepseek_llm = ChatDeepSeek(\n",
    "    model=\"deepseek-chat\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")\n",
    "\n",
    "chained_LLM  = prompt_template | deepseek_llm\n",
    "\n",
    "## Execute a prompt with LLM\n",
    "response = chained_LLM.invoke({\n",
    "    \"msgs\": [HumanMessage(content=\"I love programming.\")],\n",
    "    \"language\": \"French\"\n",
    "})\n",
    "response.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8af8dd",
   "metadata": {},
   "source": [
    "---\n",
    "## AI Agent\n",
    "- AI agent can not only use it's knowledge to answer the question, but it can also act on some task. \n",
    "- LLM can be equipped with many tools can perform tasks\n",
    "- Check support for tool calling before using with LLM\n",
    "- There are some open source [Tools](https://python.langchain.com/docs/integrations/tools/) available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6659e10f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "You are a helpful assistant.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is Vimal Menon email address.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  check_email (call_0_662834ab-cf90-4e64-8e29-d164c29a7c13)\n",
      " Call ID: call_0_662834ab-cf90-4e64-8e29-d164c29a7c13\n",
      "  Args:\n",
      "    name: Vimal Menon\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "janedoe@example.com\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The email address for Vimal Menon is janedoe@example.com.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, ToolMessage\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "## Setting up Tools\n",
    "@tool\n",
    "def check_email(name:str = None) -> str:\n",
    "    \"\"\"Use this tool to get users email address.\"\"\"\n",
    "    return \"janedoe@example.com\"\n",
    "\n",
    "## Initialize DeepSeek LLM\n",
    "deepseek_llm = ChatDeepSeek(\n",
    "    model=\"deepseek-chat\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")\n",
    "\n",
    "## Bind tools to the DeepSeek LLM\n",
    "deepseek_with_tools = deepseek_llm.bind_tools([check_email])\n",
    "\n",
    "## Create a prompt template for the chat\n",
    "prompt_template = ChatPromptTemplate([\n",
    "    (\"system\", \"You are a helpful assistant.\"),\n",
    "    MessagesPlaceholder(\"msgs\")\n",
    "])\n",
    "prompt_messages = prompt_template.invoke({\n",
    "    \"msgs\": [HumanMessage(content=\"What is Vimal Menon email address.\")]\n",
    "})\n",
    "\n",
    "## Invoke the DeepSeek LLM with tools\n",
    "response = deepseek_with_tools.invoke(prompt_messages)\n",
    "prompt_messages.messages.append(response)\n",
    "for tool in response.tool_calls:\n",
    "    if tool[\"name\"] == \"check_email\":\n",
    "        tool_msg = check_email.invoke(tool[\"args\"])\n",
    "        prompt_messages.messages.append(ToolMessage(tool_msg, tool_call_id=tool[\"id\"]))\n",
    "response = deepseek_with_tools.invoke(prompt_messages)\n",
    "prompt_messages.messages.append(response)\n",
    "\n",
    "for message in prompt_messages.messages:\n",
    "    message.pretty_print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fbe1f4",
   "metadata": {},
   "source": [
    "---\n",
    "## Structured Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3065bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountryList(countries=[Country(name='China', capital='Beijing', population=1439323776, states=['Anhui', 'Fujian', 'Gansu', 'Guangdong', 'Guizhou', 'Hainan', 'Hebei', 'Heilongjiang', 'Henan', 'Hubei', 'Hunan', 'Jiangsu', 'Jiangxi', 'Jilin', 'Liaoning', 'Qinghai', 'Shaanxi', 'Shandong', 'Shanxi', 'Sichuan', 'Yunnan', 'Zhejiang']), Country(name='India', capital='New Delhi', population=1380004385, states=['Andhra Pradesh', 'Arunachal Pradesh', 'Assam', 'Bihar', 'Chhattisgarh', 'Goa', 'Gujarat', 'Haryana', 'Himachal Pradesh', 'Jharkhand', 'Karnataka', 'Kerala', 'Madhya Pradesh', 'Maharashtra', 'Manipur', 'Meghalaya', 'Mizoram', 'Nagaland', 'Odisha', 'Punjab', 'Rajasthan', 'Sikkim', 'Tamil Nadu', 'Telangana', 'Tripura', 'Uttar Pradesh', 'Uttarakhand', 'West Bengal']), Country(name='United States', capital='Washington, D.C.', population=331002651, states=['Alabama', 'Alaska', 'Arizona', 'Arkansas', 'California', 'Colorado', 'Connecticut', 'Delaware', 'Florida', 'Georgia', 'Hawaii', 'Idaho', 'Illinois', 'Indiana', 'Iowa', 'Kansas', 'Kentucky', 'Louisiana', 'Maine', 'Maryland', 'Massachusetts', 'Michigan', 'Minnesota', 'Mississippi', 'Missouri', 'Montana', 'Nebraska', 'Nevada', 'New Hampshire', 'New Jersey', 'New Mexico', 'New York', 'North Carolina', 'North Dakota', 'Ohio', 'Oklahoma', 'Oregon', 'Pennsylvania', 'Rhode Island', 'South Carolina', 'South Dakota', 'Tennessee', 'Texas', 'Utah', 'Vermont', 'Virginia', 'Washington', 'West Virginia', 'Wisconsin', 'Wyoming']), Country(name='Indonesia', capital='Jakarta', population=273523615, states=['Aceh', 'Bali', 'Banten', 'Bengkulu', 'Gorontalo', 'Jakarta', 'Jambi', 'Java', 'Kalimantan', 'Lampung', 'Maluku', 'North Maluku', 'North Sulawesi', 'North Sumatra', 'Papua', 'Riau', 'Riau Islands', 'South Sulawesi', 'South Sumatra', 'Southeast Sulawesi', 'West Java', 'West Kalimantan', 'West Nusa Tenggara', 'West Papua', 'West Sulawesi', 'West Sumatra']), Country(name='Pakistan', capital='Islamabad', population=220892340, states=['Balochistan', 'Gilgit-Baltistan', 'Islamabad Capital Territory', 'Khyber Pakhtunkhwa', 'Punjab', 'Sindh'])])\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, ToolMessage\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "\n",
    "## Initialize DeepSeek LLM\n",
    "deepseek_llm = ChatDeepSeek(\n",
    "    model=\"deepseek-chat\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")\n",
    "\n",
    "# Pydantic\n",
    "class Country(BaseModel):\n",
    "    \"\"\"List countries detail.\"\"\"\n",
    "    name: str = Field(description=\"The name of the country\")\n",
    "    capital: str = Field(description=\"The capital city of the country\")\n",
    "    population: int = Field(description=\"The population of the country\")\n",
    "    states: list[str] = Field(description=\"List the states in the country\")\n",
    "\n",
    "\n",
    "class CountryList(BaseModel):\n",
    "    \"\"\"List of countries.\"\"\"\t\t\n",
    "    countries: list[Country] = Field(description=\"List of countries with their capitals and populations\")\n",
    "\n",
    "\n",
    "deepseek_llm_with_output = deepseek_llm.with_structured_output(CountryList)\n",
    "\n",
    "## Create a prompt template for the chat\n",
    "prompt_template = ChatPromptTemplate([\n",
    "    (\"system\", \"You are a helpful assistant.\"),\n",
    "    MessagesPlaceholder(\"msgs\")\n",
    "])\n",
    "prompt_messages = prompt_template.invoke({\n",
    "    \"msgs\": [HumanMessage(content=\"List out top 5 countries as per their population.\")]\n",
    "})\n",
    "\n",
    "deepseek_response = deepseek_llm_with_output.invoke(prompt_messages)\n",
    "\n",
    "pprint(deepseek_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang-family-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
